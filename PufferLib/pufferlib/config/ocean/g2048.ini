[base]
package = ocean
env_name = puffer_g2048
policy_name = G2048
rnn_name = Recurrent

[policy]
hidden_size = 512

[rnn]
input_size = 512
hidden_size = 512

[vec]
num_envs = 4

[env]
num_envs = 4096
reward_scaler = 0.67
endgame_env_prob = 0.05
scaffolding_ratio = 0.67
use_heuristic_rewards = True
snake_reward_weight = 0.0005

[train]
# 512 hidden: https://wandb.ai/kywch/pufferlib/runs/5thsjr61?nw=nwuserkywch
total_timesteps = 6_767_676_767
anneal_lr = True
min_lr_ratio = 0.15
batch_size = auto
bptt_horizon = 64
minibatch_size = 32768

clip_coef = 0.067
ent_coef = 0.0267
gae_lambda = 0.67
gamma = 0.99567
vf_clip_coef = 0.167
vf_coef = 2.0

learning_rate = 0.000467
max_grad_norm = 0.5


# These are newer puffer PPO params. Need more sweeping.
adam_beta1 = 0.99
adam_beta2 = 0.9999
adam_eps = 0.0001
prio_alpha = 0.8
prio_beta0 = 0.1
vtrace_c_clip = 2.0
vtrace_rho_clip = 1.1


### Targeted sweep

[sweep]
metric = score
goal = maximize
max_suggestion_cost = 7200
sweep_only = endgame_env_prob, scaffolding_ratio, snake_reward_weight, learning_rate, max_grad_norm
downsample = 1

[sweep.env.endgame_env_prob]
distribution = uniform
min = 0.0
mean = 0.03
max = 0.2
scale = auto

[sweep.env.scaffolding_ratio]
distribution = uniform
min = 0.1
mean = 0.5
max = 0.8
scale = auto

[sweep.env.snake_reward_weight]
distribution = uniform
min = 0.0001
mean = 0.0007
max = 0.0050
scale = auto

[sweep.train.learning_rate]
distribution = uniform
min = 0.0001
mean = 0.0005
max = 0.0030
scale = 0.5

[sweep.train.max_grad_norm]
distribution = uniform
min = 0.1
mean = 0.5
max = 2.0
scale = 0.5

[sweep.train.vf_clip_coef]
distribution = uniform
min = 0.05
max = 0.5
mean = 0.2
scale = auto


### Broad sweep

; [sweep]
; metric = score
; goal = maximize

; [sweep.env.reward_scaler]
; distribution = uniform
; min = 0.1
; mean = 0.5
; max = 1.0
; scale = auto

; [sweep.env.scaffolding_ratio]
; distribution = uniform
; min = 0.0
; mean = 0.5
; max = 0.8
; scale = auto

; [sweep.env.snake_reward_weight]
; distribution = uniform
; min = 0.00001
; mean = 0.00005
; max = 0.0002
; scale = auto

; [sweep.train.total_timesteps]
; distribution = log_normal
; min = 3e8
; max = 1e10
; mean = 1e9
; scale = time

; [sweep.train.learning_rate]
; distribution = log_normal
; min = 0.00001
; mean = 0.001
; max = 0.1
; scale = 0.5

; [sweep.train.gamma]
; distribution = logit_normal
; min = 0.8
; mean = 0.995
; max = 0.9999
; scale = auto

; [sweep.train.gae_lambda]
; distribution = logit_normal
; min = 0.01
; mean = 0.7
; max = 0.995
; scale = auto

; [sweep.train.clip_coef]
; distribution = log_normal
; min = 0.001
; max = 0.5
; mean = 0.05
; scale = auto